\section{Introducción}

La Matem\'atica, como ciencia, vive y crece con el intercambio de ideas entre los cultivadores de
diferentes \'areas del conocimiento y el desarrollo del quehacer de la vida del ser humano y su
entorno; y por su puesto alimentada por investigaciones que se desarrollan d\'ia a d\'ia en 
distintos espacios de la actividad cient\'ifica.%(Ver \cite{apoyo})

La programaci\'on lineal fue planteada como un modelo matem\'atico desarrollado durante la Segunda
Guerra Mundial a fin de reducir los costos del ej\'ercito y aumentar las p\'erdidas del enemigo. Los
fundadores de la t\'ecnica son George Dantzig, quien public\'o el método simplex en 1947, John Von
Neumann, que desarroll\'o la teor\'ia de la dualidad en el mismo año y Leonid Kantor\'ovich, un
matem\'atico ruso que utiliz\'o t\'ecnicas similares aplicadas a la econom\'ia antes de Dantzig y 
que gan\'o el premio Nobel en econom\'ia en 1975. (V\'ease \cite{intro})

La teor\'ia moderna de optimizaci\'on comenz\'o esencialmente con el desarrollo del m\'etodo simplex. 

En el \'area de investigaci\'on operativa la programaci\'on lineal estudia la minimizaci\'on de una 
funci\'on lineal restringida a un conjunto definido por desigualdades lineales. Es una herramienta fundamental
gracias a:

\begin{itemize}
   \item La existencia de algoritmos eficientes de resoluci\'on como el simplex (a pesar de su 
	 complejidad no polinomial).
   \item La cantidad de problemas que entran dentro de este paradigma.
   \item La cantidad de problemas que sin ser lineales pueden ser aproximados o resueltos 
	 mediante sucesiones de \'estos.
\end{itemize}

Sin embargo existen numerosos problemas en los que las herramientas lineales no son suficientes (V\'ease \cite{orden})y 
que dan lugar al estudio de la programaci\'on no lineal. Por ejemplo:

\begin{itemize}
   \item Problemas de m\'inimos cuadrados originados en la teor\'ia de redes neuronales.
   \item Problemas de diseño estructural (mec\'anico, el\'ectrico, espacial).
   \item Problemas de control \'optimo (lanzamiento cohete-sat\'elite, planeamiento de producci\'on).
   \item Problemas de control óptimo estoc\'astico (operaci\'on de una represa, de una red de 
	 poliductos, portafolio de acciones).
   \item Problemas de ruteo en redes de transporte y telecomunicaciones.
\end{itemize}

Las funciones no diferenciables en todas partes, marcaron un paradigma en la teor\'ia moderna de
optimizaci\'on. Se encontr\'o que muchos problemas de optimizaci\'on convexa no eran diferenciables
en el punto m\'inimo. As\'i, un enfoque completamente diferente se desarroll\'o, en donde fue 
concebida la noci\'on de subdiferencial.

De esta forma los enfoques modernos de la teor\'ia de optimizaci\'on deben sus or\'igenes al 
c\'alculo de variaciones que ha sido estudiado por más de tres siglos y que tambi\'en fue crucial en
el desarrollo del an\'alisis funcional.\medskip

Los m\'etodos computacionales para la optimizaci\'on no diferenciable se desarrollaron en dos direcciones:

\begin{itemize}
   \item[a)] La investigaci\'on dirigida a resolver determinados tipos de problemas de minimizaci\'on con funciones no diferenciables que
	     tienen una estructura especial y que se define de forma expl\'icita 
   \item[b)] La investigaci\'on sobre la elaboraci\'on de m\'etodos para resolver clases m\'as generales de problemas, que no suponen de
	     antemano el conocimiento de la estructura espec\'ifica de la funci\'on a minimizar pero requieren la evaluaci\'on de la funci\'on
	     y sus gradientes (o sus an\'alogos en el caso no diferenciable) en cualquier punto dado.
\end{itemize}

Para el primer grupo, se cuenta con numerosos trabajos sobre m\'etodos para resolver problemas de minimizaci\'on. Para el segundo grupo una 
serie de obras se dedican a la minimizaci\'on de funciones convexas lineales a trozos. Para la solución de varios problemas de optimizaci\'on
no diferenciable en los que se dan expl\'icitamente los puntos donde la funci\'on no es diferenciable (por ejemplo, las funciones con valores
absolutos), se han desarrollado t\'ecnicas especiales de suavizado.
\medskip

En lo que se refiere a m\'etodos generales de optimizaci\'on no diferenciable, se pueden distinguir dos clases b\'asicas en los cuales se 
requiere el c\'alculo del subdiferencial.

\begin{enumerate}
   \item M\'etodos de gradiente generalizado. Para minimizar funciones diferenciables, se usan con frecuencia m\'ultiples versiones del 
	 m\'etodo de gradiente, que es natural, ya que la direcci\'on negativa del gradiente en un punto dado es una direcci\'on de descenso.
	 La selecci\'on de un tamaño de paso en la mayor\'ia de estos m\'etodos tiene por objeto disminuir de manera significativa el valor de 
	 la funci\'on objetivo en cada iteraci\'on.
   \item El m\'etodo de planos de corte para resolver problemas convexos. El de Kelley por ejemplo se basa en aproximaciones lineales a la
	 gr\'afica de una funci\'on convexa por medio de hiperplanos de soporte; en cada iteraci\'on el m\'etodo resuelve un problema de
	 programaci\'on lineal con un n\'umero creciente de restricciones en cada iteraci\'on.
\end{enumerate}



