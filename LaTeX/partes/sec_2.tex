\section{Secci\'on II: Condiciones de optimalidad y dualidad}

% \subsection{Problemas con restricciones de desigualdad}%de desigualdad
% 
% % Un problema sin restricciones es un problema de la forma: $\min f(x)$ sin cualquier restricci\'on al vector $\vec{x}.$ Los problemas sin
% % restricciones rara vez surgen en aplicaciones pr\'aticas. Por lo tanto, se consideran tales problemas aqui porque las condiciones de 
% % optimalidad para problemas con restricciones son una extensi\'ion l\'ogica de las codiciones para problemas sin restricciones.\\ \\
% % 
% % {\definicion Considere el problema de minimizar
% % 
% % \[\min_{x \in \mathbb{R}^n} f(x)\]
% % 
% % y sea $\overline{x} \in \mathbb{R}^n.$ Si $f(\overline{x}) \leqslant f(x)\,\,\, \forall \,x \in \mathbb{R}^n,\,\, \overline{x} $ es llamado 
% % m\'inimo local} \medskip
% 
% En esta subsecci\'on se desarrollar\'a una condici\'on necesaria de optimalidad para minimizar $f(x)$ sujeteo a $x \in S.$ M\'as tarde $S$ 
% ser\'a espec\'ificamente definido como regi\'on factible de un problema de programaci\'on no lineal de la forma
% $\displaystyle{\min_{g(x)\leqslant 0} f(x)}$ y $x \in X.$\\ \\
% \
% 
% \textbf{Condiciones geom\'etrica de optimalidad}\medskip
% 
% {\definicion Sea $S$ un conjunto no vac\'io de $\mathbb{R}^n,$ y sea $\overline{x} \in \overline{S}.$ El cono de direcci\'on factible de $S$ 
% en $\overline{x}$ denotadao por D, est\'a dado por 
% 
% \[D = \{ d: d \neq 0,\,\mbox{ y }\,\,\, \overline{x} + \lambda d \in S\,\,\, \forall \, \lambda \in (0, \delta)\, \,\mbox{para alg\'un }\,
% \delta >0\}\]
% 
% Cada vector $\vec{d} \in D$ no nulo es llamado \textbf{\itshape direcci\'on factible.} En otras palabras, dada una funci\'on
% $f: \mathbb{R}^n \longmapsto \mathbb{R}$, el \textbf{\itshape cono de mejor direcci\'on} en $\overline{x}$ denotado por $F$ est\'a dado por:
% 
% \[F = \{ d: f(\overline{x} + \lambda d) < f(x)\,\, \mbox{ para todo }\, \lambda \in (0, \delta)\,\, \mbox{ para alg\'un }\, \delta > 0 \}\]
% 
% Cada direcci\'on $d \in F$ es llamada \textbf{\itshape direcci\'on  mejorada} \'o \textbf{\itshape direcci\'on descendente} de $f$ en
% $\overline{x}.$ \label{direcciones}}\medskip
% 
% De \'esta definici\'on es claro que un peque\~no movimiento de $\overline{x}$ a lo largo de un vector $d \in D$ conduce a puntos factibles,
% mientras que un movimiento similar a lo largo del vector $d \in F$ conduce a soluciones de mejor valor objetivo.
% \medskip
% 
% {\teorema Considere el problema $\displaystyle{\min_{x \in S} f(x)}$ donde $f:\mathbb{R}^n \longmapsto \mathbb{R}$ y $S$ es un conjunto no 
% vac\'io en $\mathbb{R}^n.$
% \begin{itemize}
%    \item Suponga que $f$ es diferenciable en el punto $\overline{x} \in S.$ Si $\overline{x}$ es una soluci\'on \'optima local, 
% 	 $F_0 \cap D = \emptyset,$ donde $F_0 = \{d: \nabla f(\overline{x})^t d < 0\}$ y $D$ es el cono de direcci\'on mejorada de $S$ en
% 	 $\overline{x}.$
%    \item Inversamente, Suponga que $F_0 \cap D = \emptyset,$
% \end{itemize}
% }

\subsection{Condicion de optimalidad de Fritz John}

{\teorema \textbf{\itshape Condiciones necesarias de Fritz John \cite{no-lineal}}\\
Sea X un conjunto abierto no vac\'io en $\mathbb{R}^n$ y sea $f: \mathbb{R}^n \longmapsto \mathbb{R}$ y 
$g_i : \mathbb{R}^n \longmapsto \mathbb{R}$ para $i = 1, \ldots , m.$ Considere el  Problema P para minimizar $f(x)$ sujeto a $x \in X$ y 
$g_i(x) \leqslant 0$ para $i = 1, \ldots , m.$ Sea $\overline{x}$ una soluci\'on factible  y denotada por $I = \{i: g_(\overline{x}) = 0\}.$
Por lo tanto, suponga que $f $ y $ g_i $ para $ i \in I $son diferenciables en $ \overline{x} $ y que $ g_i $ para $ i \notin I $ son
continuas en $\overline{x}. $ Si $ \overline{x} $ resuelve el problema P localmente, existen escalares $u_0 $ y $u_i$ para $\i \in I$ tales 
que:

\begin{eqnarray*}
   u_0 \nabla f(\overline{x}) +  \sum_{i \in I} u_i \nabla g_i (\overline{x}) & = & 0\\
   u_0, u_i & \geqslant  0  & \mbox{ para  } i\in I\\
   (u_0, u_I) & \neq & (0, 0)
\end{eqnarray*}

donde $ u_I $ es el vector cuyas componentes sin $u_i$ para $i \in I.$ Por lo tanto, si $g_i$ para $i \notin I$ casi son diferenciables en
$\overline{x}$, las codiciones anteriores pueden escribirse de forma equivalente:

\begin{eqnarray*}
   u_0 \nabla f(\overline{x}) +  \sum_{i =1}^{m} u_i \nabla g_i (\overline{x}) & = & 0\\
   u_i g_i(\overline{x}) & = & 0\,\,\,\, \mbox{ para  }\, i=1, \ldots , m\\
   u_o, u_i & \geqslant & 0\,\,\, \mbox{ para  }\, i=1, \ldots , m\\
   (u_0, u) & \neq & (0, 0)
\end{eqnarray*}

donde $u$ es el vector cuyas componentes son $u_i $ para $ i=1, \ldots , m. $ \label{fritz-nec}}
\medskip

{\teorema \textbf{\itshape Condiciones suficientes de Fritz John \cite{no-lineal}}\\
Sea $X$ un conjunto abierto no vac\'io en $\mathbb{R}^n$ y sea $f: \mathbb{R}^n \longmapsto \mathbb{R}$ y 
$g_i : \mathbb{R}^n \longmapsto \mathbb{R}$ para $i = 1, \ldots , m.$ Considere el  Problema P para minimizar $f(x)$ sujeto a $x \in X$ y 
$g_i(x) \leqslant 0$ para $i = 1, \ldots , m.$ Sea $\overline{x}$ una soluci\'on FJ denotada por $I = \{i: g_i(\overline{x}) = 0\}.$ Se
define $S$ como la regi\'on relajada y factible par el problema $P$ en el que se eliminan las restricciones no vinculantes.% FJ=sol de 
%condiciones necesarias

\begin{itemize}%definir seudoconvexas en seccion 4.4
   \item[a.] Si existe un $\varepsilon-$vecindario $N_{\varepsilon}(\overline{x}),\,\,\, \varepsilon > 0,$ tal que $f$ es seudoconvexa sobre 
   $N_{\varepsilon}(\overline{x}) \cap S,\,\, \overline{x} $ es un m\'inimo local para el problema $P.$
   \item[b.] Si $f$ es seudoconvexa en $\overline{x} $ y si $g_i,\,\, i \in I$ ambas son estrictamente pseudoconvexas y cuasiconvexas en 
   $\overline{x}, $ entonces $\overline{x} $ es una soluc\'ion \'optima global para el problema $P.$ En particular, si \'estas suposiciones de
   convexidad generalizada s\'olo son v\'alidas restringiendo el dominio de $f$ para $N_{\varepsilon}(\overline{x}) $ para alg\'un 
   $\varepsilon > 0,\,\,\, \overline{x}$ es un m\'inimo local para el problema $P.$
   \end{itemize}
\label{fritz-suf}}

\medskip

\textbf{Condiciones de Karush-Kuhn-Thucker \cite{no-lineal}}\\ \\ 

{\teorema \textbf{\itshape (Condiciones necesarias de Karush-Kuhn-Thucker KKT)}\\
Sea $X$ un conjunto abierto no vac\'io en $\mathbb{R}^n$ y sea $f: \mathbb{R}^n \longmapsto \mathbb{R} \mbox{ y }
g_i: \mathbb{R}^n \longmapsto \mathbb{R}\,\, \mbox{ para }\, i = 1, \ldots , m.$ Considere el problema $P$ para minimizar $f(x)$  sujeto a
$x\in X$ y $g_i(x) \leqslant 0,\,  \mbox{ para }\, i = 1, \ldots , m.$ Sea $\overline{x}$ una soluci\'on factible y denotada por 
$I = \{i: g_i(\overline{x}) = 0\}.$ Suponga que $f$ y $g_i$ para $i \in I$ son diferenciables en $\overline{x}$ y que $g_i$ para $i \notin I$
son continuas en $\overline{x}.$ Por lanto, suponga que $\nabla g_i(\overline{x})$ para $i \in I$ son linealmente independientes. Si 
$\overline{x}$ resuelve localmente el problema $P,$ existen escalares $u_i$ para $i \in I$ tal que 

\begin{eqnarray*}
   \nabla f(\overline{x}) + \displaystyle{\sum_{i \in I} \nabla g_i(\overline{x})} & = & 0\\
   u_i & \geqslant & 0\,\, \mbox{ para } \, i \in I
\end{eqnarray*}

Adem\'as de las suposiciones anteriores, si para cada $g_i$ con $i \notin I$ es casi diferenciable en $\overline{x},$ las condiciones 
anteriores pueden escribirse de forma equivalente como:

\begin{eqnarray*}
   \nabla f(\overline{x}) + \displaystyle{\sum_{i = 1}^{m} \nabla g_i(\overline{x})} & = & 0\\
   u_ig_i(\overline{x})  & = & 0\,\, \mbox{ para } \, i \in I\\
   u_i & \geqslant & \,\, \mbox{ para } \, i \in I
\end{eqnarray*} \label{KKT}}
\medskip

\input{./partes/sub_sec/sec2_2.tex}			%Problemas con restricciones de igualdad y desigualdades
\input{./partes/sub_sec/sec2_3.tex}			%Condici\'on suficiente y necesaria para problemas con restricciones de segundo orden
\input{./partes/sub_sec/sec2_4.tex}			%Dualidad lagrangiana



