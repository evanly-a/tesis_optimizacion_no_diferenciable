\subsection{Funciones convexas diferenciables}

{\definicion \cite{no-lineal} Sea $S$ un conjunto no vac\'io en $\mathbb{R}^n,$ y sea $f: S \longmapsto \mathbb{R}.$ Entonces $f$ se dice que es diferenciable
en $\overline{x} \in \mathring{S}$ si existe un vector $\nabla f(\overline{x}),$ llamado vector gradiente; y una funci\'on
$\alpha: \mathbb{R}^n \longmapsto \mathbb{R}$ tal que:

$$f(x) = f(\overline{x}) + \nabla f(\overline{x})^t (x - \overline{x}) + \parallel x - \overline{x} \parallel
\alpha \langle \overline{x}; x - \overline{x}\rangle \,\,\, \forall \, x \in S$$

d\'onde $\displaystyle{\lim_{x \rightarrow \overline{x}} \alpha \langle \overline{x}, x - \overline{x} \rangle = 0.}$ \label{def-dif}}
\medskip

La funci\'on $f$ se dice que es diferenciable en $S' \subseteq S$ si \'esta es diferenciable en cada punto de $S'.$ Esta representaci\'on de 
$f$ es llamada {\it expansi\'on (serie de Taylor) de primer orden} de $f$ en el punto $\overline{x}.$
\\
Note que si $f$ es diferenciable en $\overline{x},$ solo podr\'ia haber un vector gradiente el cual est\'a dado por:

$$\nabla f(\overline{x}) = \left( \dfrac{\partial f(\overline{x})}{\partial x_1}, \dots , 
\dfrac{\partial f(\overline{x})}{\partial x_n}\right)^t \equiv (f_1(\overline{x}), \ldots , f_n(\overline{x}))^t$$

d\'onde $f_i(\overline{x}) = \dfrac{\partial f(\overline{x})}{\partial x_i}$ es la derivada parcial de $f$ respecto a $x_i$ en $\overline{x}$.
\medskip

{\teorema Sea $f$ una funci\'on convexa definida en un conjunto convexo $S$ de $\mathbb{R}^n$ y sea $x$ un punto interior de $S.$ $f$ es 
diferenciable en $x$ si y s\'olo si posee un \'unico subgradiente en $x.$ En tal caso $\partial f(x) = \{\nabla f(x)\}.$ 
\label{one-subgradiente} }

%revisar la importacia de los teoremas anteriores para llegara este resultado. Non linear programacion
\medskip

{\teorema Sea $S$ un conjunto abierto no vac\'io en $\mathbb{R}^n$ y sea $f: S \longmapsto \mathbb{R}$ diferenciable en $\mathbb{R}$. Entonces
$f$ es convexa si y s\'olo si para cualquier $\overline{x} \in S$ se tiene:
$$f(x) \geqslant f(\overline{x}) + \nabla f(\overline{x})^t(x - \overline{x})\,\,\,\, \forall x \in S$$

De igual forma, $f$ es estrictamente convexa si y s\'olo si para cada $x \in S$ se tiene:
$$f(x) > f(\overline{x}) + \nabla f(\overline{x})^t(x - \overline{x})\,\,\,\, \forall x \neq \overline{x} \in S$$ \label{carac1}}
\medskip

El siguiente teorema da una carcterizaci\'on suficiente y necesaria para funciones convexas. Para una funci\'on $f$ de una variable, la 
caracterizaci\'on se reduce a una pendiente creciente.\\ 

{\teorema Sea $S$ un conjunto abierto no vac\'io en $\mathbb{R}^n$ y sea $f: S \longmapsto \mathbb{R}$ diferenciable en $S.$ Entonces $f$ es
convexa si y s\'olo si para cada $x_1, x_2 \in S$ se tiene:
$$[\nabla f(x_2) - \nabla f(x_1)]^t (x_2 - x_1) \geqslant 0.$$

Similarmete, $f$ es esrictamente convexa para cualquier $x_1, x_2 \in S$ distintos, entonces se tiene:
$$[\nabla f(x_2) - \nabla f(x_1)]^t (x_2 - x_1) \geqslant 0.$$ \label{carac2}}
\medskip

Aunque los teoremas (\ref{carac1}) y (\ref{carac2}) dan una caracterizaci\'on suficiente y necesaria para funciones convexas, comprobar
estas condiciones desde el punto de vista computacional es muy dif\'icil. Una caracterizaci\'on m\'as simple y manejable, al menos para 
funciones cuadr\'aticas puede obtenerse siempre que la funci\'on sea dos veces diferenciable. \\ \

\textbf{Funciones dos veces diferenciables} \cite{no-lineal}\\
\medskip

Una funci\'on $f$ que es diferenciable en $\overline{x}$ se dice que es dos veces diferenciable en $\overline{x}$ si la representaci\'on de la
{\it expansi\'on de segundo orden (serie de Taylor)} de la siguiente definici\'on existe.\\ 
\medskip

{\definicion Sea $S$ un conjunto no vac\'io en $\mathbb{R}^n$ y sea $f: S \longmapsto \mathbb{R}.$ Entonces $f$ se dice que es {\itshape dos
veces diferenciable} en $\overline{x} \in \mathring{S}$ si existe un vector $\nabla f(\overline{x}),$ y una matriz sim\'etrica 
$H( \overline{x} )$ de $n \times n,$ llamada {\bf{\itshape matriz hessiana}} y una funci\'on $\alpha:\mathbb{R}^n \longmapsto \mathbb{R}$ tal que:

$$f(x) = f(\overline{x}) + \nabla f(x)^t (x-\overline{x}) + \dfrac{1}{2} (x-\overline{x}) H(\overline{x}) (x-\overline{x}) + 
\parallel x-\overline{x} \parallel ^2 \alpha \langle \overline{x}, x-\overline{x} \rangle$$

para cada $x \in S,$ donde $\displaystyle{\lim_{x\longmapsto \overline{x}} \alpha \langle \overline{x}, x-\overline{x} \rangle = 0}.$ \\
La funci\'on $f$ se dice dos veces diferenciable en el conjunto abierto $S' \subseteq S$ si es dos veces diferenciable en cada punto de $S'.$
\label{dos-dif}} \\

Cabe se\~nalar que para funciones dos veces diferenciables, la matriz hessiana $H(\overline{x})$ est\'a compuesta por las derivadas parciales
de orden dos $f_{ij}(\overline{x}) \equiv \dfrac{\partial^2 f(\overline{x})}{\partial x_i \partial x_j};\,\, i = 1, \ldots , n.
\,\, j=1,\ldots , n$ y est\'a dada de la siguiente forma:

\[H(\overline{x}) = \begin{bmatrix}
                       f_{11}(\overline{x}) & f_{12}(\overline{x}) & \ldots & f_{1n}(\overline{x})\\
                       f_{21}(\overline{x}) & f_{22}(\overline{x}) & \ldots & f_{2n}(\overline{x})\\
                       \vdots               &  \vdots 		   & \ddots &  \vdots \\
                       f_{n1}(\overline{x}) & f_{n2}(\overline{x}) & \ldots & f_{nn}(\overline{x})
                    \end{bmatrix}
\]


~ \medskip


